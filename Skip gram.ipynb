{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNWPZ+DV/LHgg1/9zxNfRg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jerryson520/Word2Vec-from-scratch/blob/main/Skip%20gram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SMX4d3kgoDqJ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.datasets import DATASETS\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import Counter, defaultdict\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "import gensim.downloader\n",
        "from torch import FloatTensor as FT\n",
        "\n",
        "# Get the interactive Tools for Matplotlib\n",
        "%matplotlib notebook\n",
        "%matplotlib inline\n",
        "\n",
        "plt.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp4v1oijo513",
        "outputId": "7870a07d-d57c-439b-a763-8851ab24728c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "b2i89xXpxMVh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipGramNegativeSampling(nn.Module):\n",
        "  def __init(self, vocab_size, embed_dim):\n",
        "    super(SkipGramNegativeSampling, self).__init__()\n",
        "    self.A = nn.Embedding(vocab_size, embed_dim) # select context words\n",
        "    self.B = nn.Embedding(vocab_size, embed_dim) # select output words\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "    init_range = 0.5\n",
        "    self.A.weight.data.uniform_(-init_range, init_range)\n",
        "    self.B.weight.data.uniform_(-init_range, init_range)\n",
        "\n",
        "  def forward(self, x):\n",
        "    wc, wo = x[:, 0], x[:, 1]\n",
        "\n",
        "    a = self.A(wc) # (batch_size, embed_dim)\n",
        "\n",
        "    b = self.B(wo) # (batch_size, embed_dim)\n",
        "\n",
        "    logits = (a * b).sum(dim = -1)\n",
        "\n",
        "    return logits"
      ],
      "metadata": {
        "id": "6C0oD1fDo6Hw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ngc_ZFCdxI35"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}